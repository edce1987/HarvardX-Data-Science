---
title: "Report on the Prediction of Bank Churners"
subtitle: "Data Science: Capstone - Choose Your Own Project"
author: "by Edin Ceman"
date: "17th February 2021"
output: 
  pdf_document:
    latex_engine: xelatex
mainfont: Calibri Light 
---
```{r, message=FALSE, echo=FALSE, warning=FALSE}
load(file = "C:/Users/edin.ceman/Documents/GitHub/HarvardX-Data-Science/09_Capstone/CYO/EnvironmentClean.RData")
```

```{r, message=FALSE, echo=FALSE, warning=FALSE}
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org", dependencies = TRUE)
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org", dependencies = TRUE)
if(!require(Rborist)) install.packages("Rborist", repos = "http://cran.us.r-project.org", dependencies = TRUE)
if(!require(rpart)) install.packages("rpart", repos = "http://cran.us.r-project.org", dependencies = TRUE)
if(!require(DataExplorer)) install.packages("DataExplorer", repos = "http://cran.us.r-project.org", dependencies = TRUE)
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org", dependencies = TRUE)
if(!require(curl)) install.packages("curl", repos = "http://cran.us.r-project.org", dependencies = TRUE)
if(!require(ggplot2)) install.packages("ggplot2", repos = "http://cran.us.r-project.org", dependencies = TRUE)
```

# 1. Introduction
The following report will give you an overview of my *Data Science: Capstone Choose Your Own* project. In the **Introduction** section, background information on the *Bank Churners* use case is provided. This is followed by a description of the used data set, the goal of the project and the key steps that were performed. In the **Methods & Analysis** section, the modeling approach, process and methods will be explained. The **Results** section will then present and discuss the final results of the prediction model. Finally, the **Conclusion** section will summarize the outcomes and discuss it's limitations and potential future work. Please note that for the report at hand and the depicted R code, all comments have been removed for the purpose of clarity and formatting. The commented code and further details can be found in the corresponding R script.

## 1.1 The Bank Churners Use Case
A manager at a bank is concerned with more and more customers leaving their credit card services (i.e. *churning*). The bank manager would like to predict which customer is going to churn next based on the underlying data that the bank has collected. The bank manager's goal is to identify likely-to-churn customers such that the bank can proactively contact the customer to provide a customized service or a special offer to prevent him from churning. The bank manager asks for your support in the creation of an appropriate model that can accomplish this task. The data set is originally from a website with the URL https://leaps.analyttica.com/home. The following context and background information is taken from the Kaggle description[^1]. I have added further information and summarized it such that it conveys the key information.

[^1]: Source: https://www.kaggle.com/sakshigoyal7/credit-card-customers. 

## 1.2 Dataset
The *Bank Churners* data set contains **10,127 bank customers** with information about e.g. their *age*, *salary*, *marital_status*, *credit card limit*, *credit card category* and many more. In total there are **23 variables** in the data set. The following list gives you an overview of the variables, their data types[^2] and a brief description.

[^2]: Please note that int = integer, num = numerical and factor = discrete type or factor.

* **CLIENTNUM**, (int), unique customer ID.
* **Attrition_Flag**, (Factor w/ 2 levels "Attrited Customer", "Existing Customer"), flag if customer churned.
* **Customer_Age**, (int), age of the customer.
* **Gender**, (Factor w/ 2 levels "F","M"), sex of customer.
* **Dependent_count**, (int), number of dependents.
* **Education_Level**, (Factor w/ 7 levels "College","Doctorate"), education level of customer.
* **Marital_Status**, (Factor w/ 4 levels "Divorced","Married"), marital status.
* **Income_Category**, (Factor w/ 6 levels "), discrete income level e.g. $60K - $80K.
* **Card_Category**, (Factor w/ 4 levels "Blue","Gold"), tier of credit card product.
* **Months_on_book**, (int), period / length of relationship with bank.
* **Total_Relationship_Count**, (int), total no. of products held by the customer.
* **Months_Inactive_12_mon**, (int), no. of months inactive in the last 12 months.
* **Contacts_Count_12_mon**, (int), no. of contacts in the last 12 months.
* **Credit_Limit**, (num), credit limit on the credit card.
* **Total_Revolving_Bal**, (int), total revolving balance on the credit card.
* **Avg_Open_To_Buy**, (num), open to buy credit line (average of last 12 months).
* **Total_Amt_Chng_Q4_Q1**, (num), change in transaction amount (Q4 over Q1).
* **Total_Trans_Amt**, (int), total transaction amount (last 12 months).
* **Total_Trans_Ct**, (int), total transaction count (last 12 months).
* **Total_Ct_Chng_Q4_Q1**, (num), change in transaction count (Q4 over Q1).
* **Avg_Utilization_Ratio**, (num), average card utilization ratio.

## 1.3 Goal
The goal is to build a prediction model based on the provided *Bank Churners* data set. Following that, the aim of the prediction model is to predict potentially churning bank customers, i.e. precisely the variable *Attrition_Flag*. For the use case at hand, this is a valuable information to the bank since it can use this insight to proactively initiate countermeasures in order to prevent the customer from churning. To achieve this goal, we will build a model that learns on the basis of the existing *Bank Churners* data, and thus finds patterns to identify the parameters that indicate a potential churn.

## 1.4 Key Steps
To build and evaluate the prediction model, the following key steps are performed:

* **Data Initiation:** First, the *Bank Churners* data set is downloaded, and the relevant information is extracted, transformed and loaded into R. 

* **Data Exploration:** Subsequently, the data set and it's data structure are explored with statistics and visual representations of important metrics. Furthermore, the data set is checked for completeness and special characteristics.

* **Data Preparation:** The data set is then cleansed, and split into a *train set* (80%) for the purpose of development and training, and a hold-out *test set* (20%) for the evaluation of the prediction model.

* **Model Design:** In this step, the prediction model is built using the *train set*, and evaluated with the *test set*. Multiple machine learning techniques as well as an ensemble model are considered in the model design to find the best approach for the prediction of bank churners.

* **Model Evaluation:** Next, predictions are made on the *test set* by the each of the different techniques and approaches. Those are evaluated using a confusion matrix. From the confusion matrix selected parameters such as the *Accuracy* and the *F-measure* or *F-score* are considered for the evaluation of the models' performances.

* **Results:** The final model results as well as further insights are presented and discussed.

* **Conclusion:** The report results are summarized, and limitations as well as potential future work is discussed.

# 2. Methods & Analysis
This section explains the approach for initiating and preparing the data set as well as the designing, training and evaluation of the prediction model. The *Data Initiation*, *Data Exploration* and *Data Preparation* sections describe how the *Bank Churners* data is loaded, analyzed and prepared. Based on that, the section *Model Design* describes the approach, rationale and the methods used to build the prediction model. The *Model Evaluation* section describes the evaluation and optimization process and the metrics used to determine the model performance.

## 2.1 Data Initiation
The code shown below downloads the *Bank Churners* data set from my personal *GitHub Repository*, and extracts and transforms the relevant information into an R data frame called *data*. It should be noted that the data set has a header, and that all *string* data types are automatically transformed in a *factor* data type. This step is necessary to enable us to use classification models later on. Furthermore, from the *Bank Churners* website on Kaggle that is mentioned above, we receive the information from the author that the variables with the name  *Naive_Bayes_Classifier...mon_1* and *Naive_Bayes_Classifier...mon_2* should be removed from the data set. This cleansing step is also done as part of the following code. The cleansed data set is then assigned the name *data_clean*. 

```{r, eval=FALSE}
data <- read.csv(curl("https://raw.githubusercontent.com/edce1987/edx_edcem_,
CYO/main/BankChurners.csv"), header = TRUE, stringsAsFactors =  TRUE)

data_clean <- data %>% select(-Naive_Bayes_Classifier_Attrition_Flag_Card_Cate,
gory_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_,
mon_1 & -Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_,
mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2)
```

```{r, echo=FALSE, message=FALSE}
data <- read.csv(curl("https://raw.githubusercontent.com/edce1987/edx_edcem_CYO/main/BankChurners.csv"), header = TRUE, stringsAsFactors =  TRUE)

data_clean <- data %>% select(-Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1 & -Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2)
```

## 2.2 Data Exploration
In this section, the *Bank Churners* data set is explored in more detail. Personally, I prefer to use the package **DataExplorer** for a detailed analysis. It is a very powerful package that quickly generates a detailed report for a given data set. The report includes some important information such as histograms for the variables, QQ plots, information on missing values, variable correlations and a principal component analysis. For the report at hand, we will perform some of the exploration steps manually.

```{r, message=FALSE}
plot_intro(data_clean, title = "Data Exploration - Basics")
```

From this illustration, we see that the data set has **29% discrete columns** (i.e. factor types), and **71% continuous columns** (i.e. numerical or integer). We can also see that there are no missing values, and that the rows are complete. To have a more detailed overview on missing values, we can perform a deeper analysis using the following code:

```{r, message=FALSE}
plot_missing(data_clean, title = "Data Exploration - Missing Values")
```

In this plot we can see a more detailed overview of missing values for each variable. However, since there are no missing values for the variables, we don't need to perform further steps to e.g. fill or replace them. 

Another important information is the distribution of the values for each of the variables. By using a **histogram**, we can visually inspect the distributions to see if the variables' values are e.g. normally distributed and what kind of special characteristics they show.

```{r, message=FALSE}
plot_histogram(data_clean, title = "Data Exploration - Histogram")
```

From this plot, we can see that most of the variables in our data set are **not** normally distributed. However, an example of an approximately normal distributed variable is the *Customer_Age*. With this knowledge, we should avoid using models or techniques that strictly require the data to be normally distributed. We can gain further insights by looking deeper into a selected set of variables.

```{r, message=FALSE}
plot_bar(data_clean, title = "Data Exploration - Exemplary Variable Characteristics")
```

Here we can gain more insights about the characteristics of a selected set of variables with a factor data type. For example, we see that for our target variable *Attrition_Flag* the majority has the characteristic *Existing Customer*, whereas we are more interested in the outcome *Attrited Customer*. This "prevalence" will be discussed later on and it's impact on our results.

```{r, message = FALSE}
mean(data_clean$Attrition_Flag == "Attrited Customer")
```

From the variable *Gender*, we can see that most customers are female. From the variable *Income_Category*, we can see that most customers have an income *Less than $40k*. Most customers are married according to the variable *Marital Status*. Most customers have a *Blue* card category.

Of course, we could go into even more detail at this point and e.g. perform correlation analyses for the variables and try to perform a dimensionality reduction using a principal component analysis (PCA). However, I have scoped those steps out and decided to simplify the model design process in this regard. Hence, we will apply the selected machine learning techniques and approaches on the full-size and unrestricted *Bank Churners* data set, and evaluate how the selected models perform in this case. A deeper analysis can be done as part of future work as described in the section *4. Conclusion*.

\newpage
## 2.3 Data Preparation
Since in the previous section we observed that there are no missing values in the data set, and that the rows and columns are complete, we do not have to perform further steps for e.g. filling of NAs. However, it makes sense to remove the variable *CLIENTNUM* which is a unique ID for each customer. Since this is a randomly assigned and unique ID, it is plausible to expect that is has no explanatory power. Since no e.g. *joins* are performed later on, we also do not need it for mapping purposes. Also, we want to avoid causing a potential interference for the models. Hence, we remove the *CLIENTNUM* from the data set and receive the set *data_prepared*. 

```{r, message = FALSE}
data_prepared <- data_clean %>% select(-CLIENTNUM)
rm(data, data_clean)
```

From here, we can move further and prepare the data set for the subsequent model design. We split the set *data_prepared* it into a *train set* (80%) (or 8,101 observations) and a *test set* (20%) (or 2,026 observations). The *train set* is used for the purpose of model design and training, whereas the *test set* is used for the model evaluation and parameter optimization.

```{r, eval = FALSE}
set.seed(1, sample.kind="Rounding")

test_index <- createDataPartition(data_prepared$Attrition_Flag, 
                                  times = 1, p = 0.2, list = FALSE)
train_set <- data_prepared[-test_index,]
test_set <- data_prepared[test_index,]
```

```{r, message=FALSE, echo=FALSE, warning=FALSE}
set.seed(1, sample.kind="Rounding")
test_index <- createDataPartition(data_prepared$Attrition_Flag, times = 1, p = 0.2, list = FALSE)
train_set <- data_prepared[-test_index,]
test_set <- data_prepared[test_index,]
```

\newpage
## 2.4 Model Design
We want to design a model that predicts a churning customer using our prepared *train set*. The target variable we want to predict is *Attrition Flag*. This is a discrete type variable and can have two different outcomes or levels. One outcome is *Attrited Customer*, the other is *Existing Customer*. From our previous data exploration, we know that the outcome *Attrited Customer* has a prevalence of ~16%, i.e. those customers churned according to the data set. Hence, we need a model type that is suitable for **classification** since we have a discrete target variable here that can only have one of the two mentioned outcomes or levels. To find suitable classification models, we can inspect the list of available models from the *caret* package. The following excerpt shows a set of exemplary models.

```{r, message = FALSE}
mod <- modelLookup()
mod <- mod %>% filter(forClass == TRUE)
head(mod)
```
Since we do not know yet which model will perform best on our *Bank Churners* data set, we will select some popular models and evaluate them in a later step.

We will evaluate the following set of selected models[^3]:

* **adaboost:** Adaptive Boosting
* **bayesglm:** Bayes Generalized Linear Model
* **knn:** K-Nearest Neighbors
* **naive_bayes:** Naive Bayes
* **Rborist:** Extensible and parallelizable implementation of Random Forest
* **rf:** Random Forest
* **rpart:** Recursive Partitioning and Regression Trees
* **svmLinear:** Support Vector Machine Linear
* **svmPoly:** Support Vector Machine Polynomial
* **svmRadial:** Support Vector Machine Radial

```{r, eval = FALSE}
models <- c("adaboost", "bayesglm", "knn", "naive_bayes", "Rborist", "rf", 
            "rpart", "svmLinear", "svmPoly", "svmRadial")
```

```{r, message = FALSE, echo = FALSE}
models <- c("adaboost", "bayesglm", "knn", "naive_bayes", "Rborist", "rf", "rpart", "svmLinear", "svmPoly", "svmRadial")
```

[^3]: Explaining each model in more detail would go beyond the scope of this report. Hence, the selected models will only be listed here.

Each of the selected models will be trained (or fitted) on our prepared *train set*. Each model will be trained using all available variables (or features). To avoid **overfitting**, we will make use of *k-fold cross-validation*. Overfitting arises when a model is too specific, i.e. such that it performs well on a well known data set, but rather poorly on an unknown data set. The concept of *k-fold cross-validation* is a procedure that resamples a given data set **k** times to reduce a potential **selection bias** (or to increase generalization) when deciding which part of your data you use for training and which one for test purposes[^4].

[^4]: Further information: https://towardsdatascience.com/why-and-how-to-cross-validate-a-model-d6424b45261f.

For our model design and training, we will use a 10-fold cross-validation. 

```{r, message=FALSE, warning=FALSE}
set.seed(1, sample.kind="Rounding")
control <- trainControl(method = "cv", number = 10, p = .8)
```

Following that, the models are fitted based on the *train set* and predictions for the target variable *Attrition_Flag* are made with each of the models for the *test set*.